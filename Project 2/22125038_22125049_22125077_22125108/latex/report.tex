\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{pgffor}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{pifont}
\usepackage{amssymb}
\usepackage{array}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{fancyhdr}
\usepackage{colortbl}
\usepackage{multicol}
\usepackage{longtable}
\usepackage{cite}
\usepackage{float}
\usepackage{tabularx}
\usepackage[vietnamese, english]{babel}
\usepackage[a4paper, total={6in, 8in}, margin=1in]{geometry}
\usepackage{styles/standard}

\allowdisplaybreaks
\setlength{\parindent}{0pt}
\setlength{\headheight}{40pt}
\setlength{\parskip}{0.3em}
\renewcommand{\arraystretch}{1.6}

\title{ \normalsize \textsc{}
		\\ [2.0cm]
        % \HRule{1.5pt} \\
        \begin{tabular}{c@{\hskip 2cm}c}
            \includegraphics[width=0.3\textwidth]{styles/logoHCMUS.png}
            &
            \includegraphics[width=0.3\textwidth]{styles/logoAPCS.png}
        \end{tabular}
        \vspace{2em} \\
        \vspace{6pt}
        \LARGE \textbf{\uppercase{CS420 -- Artificial Intelligence}} \\
		\LARGE \textbf{Project 2 -- Decision Tree} \\
        \Large \textbf{Report} \\
        \vspace*{13\baselineskip}
}
\author{
    VNUHCM-UNIVERSITY OF SCIENCE \\
    \today
}
\date{}

\pagestyle{fancy}
\fancyhead[L]{\textbf{Project 2 -- Decision Tree}}
\fancyhead[R]{\includegraphics[width=1.25cm]{styles/logoAPCS.png}}

\begin{document}

\maketitle
\thispagestyle{empty}
\newpage

\selectlanguage{vietnamese}
\thispagestyle{empty}
\section*{Student Information}
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Full Name} & \textbf{Student ID} \\ \hline 
        Vòng Vĩnh Toàn & 22125108 \\ \hline
        Nguyễn Hoàng Phúc & 22125077\\ \hline
        Huỳnh Hà Phương Linh & 22125049\\ \hline
        Huỳnh Đăng Khoa & 22125038 \\ 
        \hline
    \end{tabular}
\end{table}
\selectlanguage{english}
\newpage

\tableofcontents
\thispagestyle{empty}
\newpage

\setcounter{page}{1}
\Section{Introduction}

The Decision Tree algorithm is a supervised learning algorithm that can be used for both classification and regression tasks. The algorithm works by recursively splitting the dataset into subsets based on the most discriminative features. The splitting process continues until the tree reaches a maximum depth or the number of samples in a node falls below a certain threshold. The Decision Tree algorithm is simple to understand and interpret, making it an excellent choice for tasks that require transparency and interpretability.

In this project, we implement the Decision Tree algorithm using Python and the \texttt{scikit-learn} library. We evaluate the algorithm's performance on three different datasets from the UCI Machine Learning Repository. The datasets are as follows:
\begin{enumerate}
    \item The UCI Breast Cancer Wisconsin dataset \cite{breast_cancer_wisconsin}
    \item The UCI Wine Quality dataset \cite{wine_quality}
    \item The UCI User Knowledge Modeling dataset \cite{user_knowledge_modeling}
\end{enumerate}

Note that \textbf{all figures and tables} in this report are in the \textbf{vector image format} for better readability and quality as the reader zooms in since the illustrations can be too complex to be displayed.

\include{dataset1}

\include{dataset2}

\include{dataset3}

\newpage
\Section{Comparison}

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{|X|X|X|X|}
        \hline
        \makecell{\textbf{Criterion}} & 
        \makecell{\textbf{Breast Cancer} \\ \textbf{Wisconsin}} & 
        \makecell{\textbf{Wine} \\ \textbf{Quality}} & 
        \makecell{\textbf{User Knowledge} \\ \textbf{Modeling}} \\ \hline
        \textbf{Accuracy (80/20)} & 89\% & 77\% & 90\% \\ \hline
        \textbf{No. of Instances} & 569 & 4898 & 403 \\ \hline
        \textbf{No. of Features} & 30 & 11 & 5 \\ \hline
        \textbf{No. of Classes} & 2 & 3 & 4 \\ \hline
        \textbf{Imbalance} & Slight & Heavy & Balanced \\ \hline
        \textbf{Overfitting} & Yes & No & Slight \\ \hline
        \textbf{Complexity} & Medium & High & Medium \\ \hline
    \end{tabularx}
    \caption{Comparison of Decision Tree algorithm performance on different datasets}
\end{table}

\Section{Conclusion}

In this project, we implemented the Decision Tree algorithm using Python and the \texttt{scikit-learn} library. We evaluated the algorithm's performance on three different datasets from the UCI Machine Learning Repository.

We compared the algorithm's performance on the three datasets based on several criteria, including accuracy, number of instances, number of features, number of classes, imbalance, overfitting, and complexity.

The results show that the Decision Tree algorithm can achieve high accuracy on 2 out of 3 datasets. The algorithm performs well on the Breast Cancer Wisconsin dataset and the User Knowledge Modeling dataset, achieving an accuracy of 89\% and 90\%, respectively. However, the algorithm performs poorly on the Wine Quality dataset, achieving an accuracy of only 77\%. The poor performance on the Wine Quality dataset may be due to the dataset's complexity and the algorithm's inability to capture the underlying patterns in the data. 

The algorithm is simple to understand and interpret, making it an excellent choice for tasks that require transparency and interpretability.

\newpage
\Section{Self-evaluation}

\selectlanguage{vietnamese}
\begin{table}[H]
    \centering
    \begin{tabular}{|c|p{9cm}|c|c|}
    \hline
    \textbf{No.} & \textbf{Details} & \textbf{Score} & \textbf{Self-Evaluation} \\
    \hline
    1 & Analysis of the Wine Quality dataset.  & 30\% & 30\%\\
    \hline
    2 & Analysis of the Breast Cancer dataset. & 30\% & 30\%\\
    \hline
    3 & Analysis of an additional dataset. & 30\% & 30\%\\
    \hline
    4 & Comparative analysis of all three datasets. & 5\% & 5\%\\
    \hline
    5 & Well-structured and formatted notebooks. & 5\% & 5\%\\
    \hline
    & \textbf{Total} & 100\% & 100\% \\
    \hline
    \end{tabular}
    \end{table}
    
\Subsection{1. Wine Quality dataset}
\begin{table}[H]
    \centering
    \begin{tabular}{|c|p{9cm}|c|c|}
    \hline
    \textbf{No.} & \textbf{Details} & \textbf{Score} & \textbf{Self-Evaluation} \\
    \hline
    1 & Data preparation.  & 30\% & 30\%\\
    \hline
    2 & Implement decision tree classifiers. & 20\% & 20\%\\
    \hline
    3 & Performance evaluation of decision tree. &  & \\
    \hline
    & - Classification report and confusion matrix. & 10\% & 10\%\\
    \hline
    & - Insights. & 10\% & 10\%\\
    \hline
    4 & Depth and accuracy of decision trees. &  & \\
    \hline
    & - Visualization (trees, tables, charts). & 20\% & 20\%\\
    \hline
    & - Insights. & 10\% & 10\%\\
    \hline
    & \textbf{Total} & 100\% & 100\% \\
    \hline
    \end{tabular}
\end{table}
    
\Subsection{2. Breast Cancer dataset}
\begin{table}[H]
    \centering
    \begin{tabular}{|c|p{9cm}|c|c|}
    \hline
    \textbf{No.} & \textbf{Details} & \textbf{Score} & \textbf{Self-Evaluation} \\
    \hline
    1 & Data preparation.  & 30\% & 30\%\\
    \hline
    2 & Implement decision tree classifiers. & 20\% & 20\%\\
    \hline
    3 & Performance evaluation of decision tree. &  & \\
    \hline
    & - Classification report and confusion matrix. & 10\% & 10\%\\
    \hline
    & - Insights. & 10\% & 10\%\\
    \hline
    4 & Depth and accuracy of decision trees. &  & \\
    \hline
    & - Visualization (trees, tables, charts). & 20\% & 20\%\\
    \hline
    & - Insights. & 10\% & 10\%\\
    \hline
    & \textbf{Total} & 100\% & 100\% \\
    \hline
    \end{tabular}
\end{table}

\Subsection{3. An Additional dataset}
\begin{table}[H]
    \centering
    \begin{tabular}{|c|p{9cm}|c|c|}
    \hline
    \textbf{No.} & \textbf{Details} & \textbf{Score} & \textbf{Self-Evaluation} \\
    \hline
    1 & Data preparation.  & 30\% & 30\%\\
    \hline
    2 & Implement decision tree classifiers. & 20\% & 20\%\\
    \hline
    3 & Performance evaluation of decision tree. &  & \\
    \hline
    & - Classification report and confusion matrix. & 10\% & 10\%\\
    \hline
    & - Insights. & 10\% & 10\%\\
    \hline
    4 & Depth and accuracy of decision trees. &  & \\
    \hline
    & - Visualization (trees, tables, charts). & 20\% & 20\%\\
    \hline
    & - Insights. & 10\% & 10\%\\
    \hline
    & \textbf{Total} & 100\% & 100\% \\
    \hline
    \end{tabular}
\end{table}

\Section{Contributions}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|p{5cm}|c|c|c|}
    \hline
    \makecell{\textbf{No.}} & \makecell{\textbf{Task}} & \makecell{\textbf{Name}} & \makecell{\textbf{ID}} & \makecell{\textbf{Contribution}\\\textbf{percentage}} \\ \hline
    
    1 & Building the decision tree classifiers & \multirow{3}{*}{Vòng Vĩnh Toàn} & \multirow{3}{*}{22125108} & \multirow{3}{*}{25\%} \\ \cline{1-2}
    2 & Evaluating the decision tree classifiers &  &  &  \\ \cline{1-2}
    3 & Unifying code structure &  &  &  \\ \hline
    
    4 & Preparing the UCI User Knowledge Modeling dataset & \multirow{3}{*}{Nguyễn Hoàng Phúc} & \multirow{3}{*}{22125077} & \multirow{3}{*}{25\%} \\ \cline{1-2}
    5 & Visualize the class distributions &  &  &  \\ \cline{1-2}
    6 & The depth and accuracy of a de-
    Cision tree &  &  &  \\ \hline
    
    7 & Preparing the Wine Quality dataset & \multirow{3}{*}{\makecell{Huỳnh Hà Phương Linh}} & \multirow{3}{*}{22125049} & \multirow{3}{*}{25\%} \\ \cline{1-2}
    8 & Report preparation &  &  &  \\ \cline{1-2}
    9 & Review code &  &  &  \\ \hline
    
    10 & Preparing the Breast Cancer dataset  & \multirow{3}{*}{Huỳnh Đăng Khoa} & \multirow{3}{*}{22125038} & \multirow{3}{*}{25\%} \\ \cline{1-2}
    11 & Report preparation &  &  &  \\ \cline{1-2}
    12 & Dataset comparation &  &  &  \\ \hline
    
    \end{tabular}
\end{table}

\selectlanguage{english}
\newpage
\bibliographystyle{ieeetr}
\bibliography{references}
\addcontentsline{toc}{section}{References}

\end{document}

