\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{pgffor}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{pifont}
\usepackage{amssymb}
\usepackage{array}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{fancyhdr}
\usepackage{colortbl}
\usepackage{multicol}
\usepackage{longtable}
\usepackage{cite}
\usepackage{float}
\usepackage{tabularx}
\usepackage[vietnamese, english]{babel}
\usepackage[a4paper, total={6in, 8in}, margin=1in]{geometry}
\usepackage{styles/standard}

\allowdisplaybreaks
\setlength{\parindent}{0pt}
\setlength{\headheight}{40pt}
\setlength{\parskip}{0.3em}
\renewcommand{\arraystretch}{1.6}

\title{ \normalsize \textsc{}
		\\ [2.0cm]
        % \HRule{1.5pt} \\
        \begin{tabular}{c@{\hskip 2cm}c}
            \includegraphics[width=0.3\textwidth]{styles/logoHCMUS.png}
            &
            \includegraphics[width=0.3\textwidth]{styles/logoAPCS.png}
        \end{tabular}
        \vspace{2em} \\
        \vspace{6pt}
        \LARGE \textbf{\uppercase{CS420 -- Artificial Intelligence}} \\
		\LARGE \textbf{Project 2 -- Decision Tree} \\
        \Large \textbf{Report} \\
        \vspace*{13\baselineskip}
}
\author{
    VNUHCM-UNIVERSITY OF SCIENCE \\
    \today
}
\date{}

\pagestyle{fancy}
\fancyhead[L]{\textbf{Project 2 -- Decision Tree}}
\fancyhead[R]{\includegraphics[width=1.25cm]{styles/logoAPCS.png}}

\begin{document}

\maketitle
\thispagestyle{empty}
\newpage

\selectlanguage{vietnamese}
\thispagestyle{empty}
\section*{Student Information}
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Full Name} & \textbf{Student ID} \\ \hline 
        Vòng Vĩnh Toàn & 22125108 \\ \hline
        Nguyễn Hoàng Phúc & 22125077\\ \hline
        Huỳnh Hà Phương Linh & 22125049\\ \hline
        Huỳnh Đăng Khoa & 22125038 \\ 
        \hline
    \end{tabular}
\end{table}
\selectlanguage{english}
\newpage

\tableofcontents
\thispagestyle{empty}
\newpage

\setcounter{page}{1}
\Section{Introduction}

The Decision Tree algorithm is a supervised learning algorithm that can be used for both classification and regression tasks. The algorithm works by recursively splitting the dataset into subsets based on the most discriminative features. The splitting process continues until the tree reaches a maximum depth or the number of samples in a node falls below a certain threshold. The Decision Tree algorithm is simple to understand and interpret, making it an excellent choice for tasks that require transparency and interpretability.

In this project, we implement the Decision Tree algorithm using Python and the \texttt{scikit-learn} library. We evaluate the algorithm's performance on three different datasets from the UCI Machine Learning Repository. The datasets are as follows:
\begin{enumerate}
    \item The UCI Breast Cancer Wisconsin dataset \cite{breast_cancer_wisconsin}
    \item The UCI Wine Quality dataset \cite{wine_quality}
    \item The UCI User Knowledge Modeling dataset \cite{user_knowledge_modeling}
\end{enumerate}

Note that \textbf{all figures and tables} in this report are in the \textbf{vector image format} for better readability and quality as the reader zooms in since the illustrations can be too complex to be displayed.

\include{dataset1}

\include{dataset2}

\include{dataset3}

\newpage
\Section{Comparison}

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{|X|X|X|X|}
        \hline
        \makecell{\textbf{Criterion}} & 
        \makecell{\textbf{Breast Cancer} \\ \textbf{Wisconsin}} & 
        \makecell{\textbf{Wine} \\ \textbf{Quality}} & 
        \makecell{\textbf{User Knowledge} \\ \textbf{Modeling}} \\ \hline
        \textbf{Accuracy (80/20)} & 89\% & 77\% & 90\% \\ \hline
        \textbf{No. of Instances} & 569 & 4898 & 403 \\ \hline
        \textbf{No. of Features} & 30 & 11 & 5 \\ \hline
        \textbf{No. of Classes} & 2 & 3 & 4 \\ \hline
        \textbf{Imbalance} & Slight & Heavy & Balanced \\ \hline
        \textbf{Overfitting} & Yes & No & Slight \\ \hline
        \textbf{Complexity} & Medium & High & Medium \\ \hline
    \end{tabularx}
    \caption{Comparison of Decision Tree algorithm performance on different datasets}
\end{table}

\Section{Conclusion}

In this project, we implemented the Decision Tree algorithm using Python and the \texttt{scikit-learn} library. We evaluated the algorithm's performance on three different datasets from the UCI Machine Learning Repository.

We compared the algorithm's performance on the three datasets based on several criteria, including accuracy, number of instances, number of features, number of classes, imbalance, overfitting, and complexity.

The results show that the Decision Tree algorithm can achieve high accuracy on 2 out of 3 datasets. The algorithm performs well on the Breast Cancer Wisconsin dataset and the User Knowledge Modeling dataset, achieving an accuracy of 89\% and 90\%, respectively. However, the algorithm performs poorly on the Wine Quality dataset, achieving an accuracy of only 77\%. The poor performance on the Wine Quality dataset may be due to the dataset's complexity and the algorithm's inability to capture the underlying patterns in the data. 

The algorithm is simple to understand and interpret, making it an excellent choice for tasks that require transparency and interpretability.

\Section{Self-evaluation}

\Section{Contributions}

What the hell is this?

\newpage
\bibliographystyle{ieeetr}
\bibliography{references}
\addcontentsline{toc}{section}{References}

\end{document}